{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc70358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "module_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "sys.path.append(os.path.dirname(module_dir))\n",
    "\n",
    "\n",
    "from modules.data import PhoneDataset\n",
    "from modules.models import ConvolutionalLocator\n",
    "from modules.training import EarlyStopping, ModelTrainer\n",
    "from modules.transforms import (\n",
    "    RandomHorizontalFlip,\n",
    "    RandomVerticalFlip,\n",
    "    RandomTranslation\n",
    ")\n",
    "from modules.utilities import (\n",
    "    get_data,\n",
    "    visualize_augmentations,\n",
    "    train_test_split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211437f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join('..', 'find_phone_data')\n",
    "seed = 0\n",
    "test_size = 0.1\n",
    "batch_size = 128\n",
    "patience = 5\n",
    "min_delta = 0.0\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam\n",
    "early_stopping = EarlyStopping(15)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "epochs = 50\n",
    "lr = 5e-4\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718cf4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths, locations = get_data(folder)\n",
    "print(image_paths[0])\n",
    "print(locations[os.path.basename(image_paths[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1665ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths, test_image_paths, train_locations, test_locations = train_test_split(\n",
    "    image_paths, locations, test_size, seed\n",
    ")\n",
    "print(train_image_paths[0])\n",
    "print(train_locations[os.path.basename(train_image_paths[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd9298",
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_transforms = v2.Compose([\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomVerticalFlip(),\n",
    "    RandomTranslation(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63edb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PhoneDataset(\n",
    "    train_image_paths,\n",
    "    aware_transforms,\n",
    ")\n",
    "\n",
    "test_dataset = PhoneDataset(test_image_paths)\n",
    "visualize_augmentations(train_dataset, train_locations, random_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e740fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = ModelTrainer(\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    early_stopping,\n",
    "    scheduler,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in = 3\n",
    "h_in, w_in = 326, 490\n",
    "\n",
    "model = torch.hub.load(\n",
    "    'pytorch/vision:v0.10.0',\n",
    "    'vgg11',\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "summary(\n",
    "    model=model,\n",
    "    input_size=(batch_size, c_in, h_in, w_in),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86acdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "in_features = model.classifier[-1].in_features\n",
    "model.classifier[6] = torch.nn.Linear(in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b31f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = ModelTrainer(\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    early_stopping,\n",
    "    scheduler,\n",
    "    device\n",
    ")\n",
    "\n",
    "model_trainer(epochs, model, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ed645",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.grad_requires = True\n",
    "\n",
    "model_trainer(epochs, model, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ecd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "train_size = len(train_dataloader.dataset)\n",
    "train_correct = 0\n",
    "for X, y in train_dataloader:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    pred = model(X)\n",
    "    correct = (torch.sum((y - pred)**2, dim=-1) < 0.05)\n",
    "    train_correct += correct.type(torch.float).sum().item()\n",
    "\n",
    "test_size = len(test_dataloader.dataset)\n",
    "test_correct = 0\n",
    "for X, y in test_dataloader:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    pred = model(X)\n",
    "    correct = (torch.sum((y - pred)**2, dim=-1) < 0.05)\n",
    "    test_correct += correct.type(torch.float).sum().item()\n",
    "\n",
    "print(f'Train set accuracy: {train_correct / train_size}')\n",
    "print(f'Test set accuracy: {test_correct / test_size}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
